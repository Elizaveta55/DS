{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "UofYlYCyM0Qk"
   },
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6soRLFOHNAwq"
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./train_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "test_data = pd.read_csv(\"./test_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "\n",
    "test_data['Gender'] = test_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "train_data['Gender'] = train_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "\n",
    "\n",
    "#print(train_data.shape)\n",
    "#train_data = train_data[:1280]\n",
    "#test_data = test_data[:1280]\n",
    "#print(train_data.shape)\n",
    "\n",
    "train_data = train_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "test_data = test_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "\n",
    "max_length_test = len(test_data.iloc[-1]['Name'])\n",
    "max_length_train = len(train_data.iloc[-1]['Name'])\n",
    "max_length = max(max_length_test, max_length_train)\n",
    "\n",
    "unique = list(set(\"\".join(train_data.iloc[:,0])))\n",
    "unique.sort()\n",
    "vocab = dict(zip(unique, range(1,len(unique)+1)))\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "vocab_new = Vocab(vocab,specials=())\n",
    "\n",
    "def data_process(raw_text_iter,max_len=128):\n",
    "  batch = []\n",
    "  for item in raw_text_iter:\n",
    "    res = []\n",
    "    for i in range(max_len):\n",
    "      if (len(item)>i):\n",
    "        res.extend([vocab_new[token] for token in tokenizer(item[i])])\n",
    "      else:\n",
    "        res.extend([0])\n",
    "    batch.append(res)\n",
    "  pad_data = torch.FloatTensor(batch)\n",
    "  return pad_data\n",
    "\n"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze5JRpuANB58",
    "outputId": "71495941-d4e8-4847-a77d-f6224bce45d7"
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(train_data.Gender.values))\n",
    "\n",
    "#Create Dataloader\n",
    "train_tensor = data_process(train_data.Name.values, embedding_size)\n",
    "train_data_normalized = torch.FloatTensor(scaler.fit_transform(train_tensor))\n",
    "tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(train_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "dataset = TensorDataset(train_data_normalized, tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]],\n",
      "       dtype=torch.float64)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ONYyJUH-NGFg"
   },
   "source": [
    "\n",
    "class noLSTM(torch.nn.Module):\n",
    "  def __init__(self, input_size=max_length, hidden_layer_size=100, output_size=2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.linear_one = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "  def forward(self, input_seq):\n",
    "        #input_seq = torch.reshape(input_seq, shape=(-1, self.input_size * input_seq.shape[0]))\n",
    "        #lstm_output.view(self.input_size * input_seq.shape, -1)\n",
    "        #lstm_out, self.hidden_cell = self.linear_one(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        x = self.linear_one(input_seq)\n",
    "        predictions = self.linear(x)\n",
    "        return predictions\n",
    "\n",
    "model = noLSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hq8LsZXq9krq"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Fz-L-13NNJ7W",
    "outputId": "c4c5b17c-272b-4041-ea43-1e7aed0cc23a"
   },
   "source": [
    "import time \n",
    "\n",
    "epochs = 50\n",
    "import torch.nn.functional as F\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "acc = []\n",
    "measures = []\n",
    "times = []\n",
    "i_array = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_epoch = time.time()\n",
    "    for item in loader:\n",
    "        seq = item[0]\n",
    "        label = item[1]\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        \n",
    "        y_pred = model(seq)\n",
    "        for j in range(y_pred.shape[0]):\n",
    "          predicted = np.argmax(F.softmax(y_pred[j].data))\n",
    "          true = np.argmax(label[j].data)\n",
    "          if (predicted == true):\n",
    "            correct+=1\n",
    "          total+=1\n",
    "        single_loss = loss_function(y_pred, label.float())\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    time_per_epoch = time.time() - start_epoch\n",
    "    f_measure = f1_loss(label, y_pred)\n",
    "    i_array.append(i)\n",
    "    writer.add_scalar(\"train_loss\", single_loss.item(), i)\n",
    "    losses.append(single_loss.item())\n",
    "    writer.add_scalar(\"train_acc\", (100 * correct / total), i)\n",
    "    acc.append((100 * correct / total))\n",
    "    writer.add_scalar(\"train_measure\", f_measure, i)\n",
    "    measures.append(f_measure)\n",
    "    writer.add_scalar(\"train_time\", time_per_epoch, i)\n",
    "    times.append(time_per_epoch)\n",
    "    for tag, parm in model.named_parameters():\n",
    "      writer.add_histogram(tag, parm.grad.data.cpu().numpy(), i)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}, accuracy: {(100 * correct / total)}, f-measure: {f_measure}, time = {time_per_epoch}')\n",
    "\n",
    "print(\"MODEL TIME EXECUTION--- %s seconds ---\" % (time.time() - start_time_model))\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.22485100, accuracy: 62.78095283834406, f-measure: 0.5258151292800903, time = 18.144066333770752\n",
      "epoch:   1 loss: 0.21679424, accuracy: 62.608058783978485, f-measure: 0.5347089171409607, time = 18.92706537246704\n",
      "epoch:   2 loss: 0.20638941, accuracy: 62.86019594659495, f-measure: 0.5311689972877502, time = 18.302782773971558\n",
      "epoch:   3 loss: 0.24706711, accuracy: 62.91782729805014, f-measure: 0.5150653123855591, time = 18.354072332382202\n",
      "epoch:   4 loss: 0.23457107, accuracy: 63.03309000096052, f-measure: 0.5284972786903381, time = 18.462736129760742\n",
      "epoch:   5 loss: 0.21160230, accuracy: 62.95985015848622, f-measure: 0.5328078866004944, time = 19.036044597625732\n",
      "epoch:   6 loss: 0.21624094, accuracy: 63.109931802900775, f-measure: 0.5314635634422302, time = 18.800137758255005\n",
      "epoch:   7 loss: 0.22728513, accuracy: 63.0823167803285, f-measure: 0.5240451097488403, time = 19.40931463241577\n",
      "epoch:   8 loss: 0.24202885, accuracy: 63.02588608202862, f-measure: 0.5164480209350586, time = 19.121344804763794\n",
      "epoch:   9 loss: 0.22288533, accuracy: 63.06550763615407, f-measure: 0.5298414826393127, time = 19.48712134361267\n",
      "epoch:  10 loss: 0.23422152, accuracy: 63.25761214100471, f-measure: 0.521334707736969, time = 18.95737385749817\n",
      "epoch:  11 loss: 0.25955060, accuracy: 63.015080203630774, f-measure: 0.506089448928833, time = 19.051394939422607\n",
      "epoch:  12 loss: 0.22780176, accuracy: 63.08591873979445, f-measure: 0.5269936323165894, time = 19.444645643234253\n",
      "epoch:  13 loss: 0.21369511, accuracy: 63.11593506867736, f-measure: 0.529464840888977, time = 19.335286617279053\n",
      "epoch:  14 loss: 0.20596398, accuracy: 63.09912592450293, f-measure: 0.5361606478691101, time = 18.661278009414673\n",
      "epoch:  15 loss: 0.22167362, accuracy: 63.13274421285179, f-measure: 0.5277878046035767, time = 17.779640436172485\n",
      "epoch:  16 loss: 0.24635845, accuracy: 63.13274421285179, f-measure: 0.5167599320411682, time = 17.833174467086792\n",
      "epoch:  17 loss: 0.25636122, accuracy: 63.08111612717318, f-measure: 0.5095023512840271, time = 18.734554290771484\n",
      "epoch:  18 loss: 0.25353822, accuracy: 63.34646047449813, f-measure: 0.516257107257843, time = 19.01409649848938\n",
      "epoch:  19 loss: 0.21771531, accuracy: 63.10152723081356, f-measure: 0.5287045836448669, time = 18.97831892967224\n",
      "epoch:  20 loss: 0.18879105, accuracy: 63.23600038420901, f-measure: 0.5436484217643738, time = 17.864834547042847\n",
      "epoch:  21 loss: 0.22676688, accuracy: 63.17956968590914, f-measure: 0.5252618193626404, time = 17.96598982810974\n",
      "epoch:  22 loss: 0.23951699, accuracy: 63.36687157813851, f-measure: 0.5206714868545532, time = 19.767430782318115\n",
      "epoch:  23 loss: 0.26776800, accuracy: 62.961050811641535, f-measure: 0.5060860514640808, time = 20.26160502433777\n",
      "epoch:  24 loss: 0.19413163, accuracy: 63.27322063202382, f-measure: 0.5405314564704895, time = 20.40126943588257\n",
      "epoch:  25 loss: 0.23414093, accuracy: 63.1843722985304, f-measure: 0.5250030159950256, time = 19.772701025009155\n",
      "epoch:  26 loss: 0.22957112, accuracy: 63.39808856017674, f-measure: 0.5218508243560791, time = 22.681657552719116\n",
      "epoch:  27 loss: 0.22658806, accuracy: 63.31764479877053, f-measure: 0.5218856334686279, time = 22.23924970626831\n",
      "epoch:  28 loss: 0.23023933, accuracy: 63.17836903275382, f-measure: 0.5263380408287048, time = 21.915672779083252\n",
      "epoch:  29 loss: 0.22923641, accuracy: 63.28162520411104, f-measure: 0.5241975784301758, time = 21.51893186569214\n",
      "epoch:  30 loss: 0.22634603, accuracy: 63.31764479877053, f-measure: 0.5230429768562317, time = 19.474655151367188\n",
      "epoch:  31 loss: 0.26785985, accuracy: 63.2059840553261, f-measure: 0.5057517886161804, time = 19.541741371154785\n",
      "epoch:  32 loss: 0.23636189, accuracy: 63.418499663817116, f-measure: 0.5188742280006409, time = 20.237279891967773\n",
      "epoch:  33 loss: 0.22259521, accuracy: 63.18797425799635, f-measure: 0.5295083522796631, time = 22.48119616508484\n",
      "epoch:  34 loss: 0.22884750, accuracy: 63.340457208721546, f-measure: 0.5262554883956909, time = 23.0862295627594\n",
      "epoch:  35 loss: 0.21994233, accuracy: 63.17836903275382, f-measure: 0.5314642786979675, time = 17.47679376602173\n",
      "epoch:  36 loss: 0.20474729, accuracy: 63.30443761406205, f-measure: 0.5395162105560303, time = 17.310425281524658\n",
      "epoch:  37 loss: 0.21947433, accuracy: 63.153155316492175, f-measure: 0.5288076400756836, time = 17.59051752090454\n",
      "epoch:  38 loss: 0.22164415, accuracy: 63.131543559696475, f-measure: 0.53383868932724, time = 17.375871896743774\n",
      "epoch:  39 loss: 0.22677626, accuracy: 63.48933819998079, f-measure: 0.5251190662384033, time = 17.433948755264282\n",
      "epoch:  40 loss: 0.20379871, accuracy: 63.36086831236192, f-measure: 0.5345269441604614, time = 17.462148666381836\n",
      "epoch:  41 loss: 0.23712149, accuracy: 63.19037556430698, f-measure: 0.5202603340148926, time = 17.50347900390625\n",
      "epoch:  42 loss: 0.22620669, accuracy: 63.38007876284699, f-measure: 0.5254712700843811, time = 17.556718826293945\n",
      "epoch:  43 loss: 0.21615563, accuracy: 63.136346172317744, f-measure: 0.532008945941925, time = 17.353122234344482\n",
      "epoch:  44 loss: 0.20940562, accuracy: 63.35366439343002, f-measure: 0.5302063226699829, time = 17.47782611846924\n",
      "epoch:  45 loss: 0.22877559, accuracy: 63.18917491115167, f-measure: 0.5247921943664551, time = 17.38975739479065\n",
      "epoch:  46 loss: 0.22351475, accuracy: 63.338055902410915, f-measure: 0.5260520577430725, time = 17.371811628341675\n",
      "epoch:  47 loss: 0.21458222, accuracy: 63.43410815483623, f-measure: 0.535076379776001, time = 17.305347204208374\n",
      "epoch:  48 loss: 0.22486912, accuracy: 63.34525982134281, f-measure: 0.5222569704055786, time = 17.578875303268433\n",
      "epoch:  49 loss: 0.21814780, accuracy: 63.27442128517914, f-measure: 0.5283175110816956, time = 17.500734567642212\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-36-e9d520db0147>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'epoch: {i:3} loss: {single_loss.item():10.8f}, accuracy: {(100 * correct / total)}, f-measure: {f_measure}, time = {time_per_epoch}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"MODEL TIME EXECUTION--- %s seconds ---\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'epoch: {i:3} loss: {single_loss.item():10.10f}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'start_time_model' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yvnvYCrydoGA"
   },
   "source": [
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    all = y_pred.shape[0]\n",
    "    sum=0\n",
    "    for i in range(all):\n",
    "      sum+=f1_loss_one(y_true[i], y_pred[i])\n",
    "    return sum/all\n",
    "\n",
    "def f1_loss_one(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    y_pred_soft = (F.softmax(((y_pred)), dim=0)).detach()\n",
    "    if y_pred_soft.ndim == 2:\n",
    "        y_pred_soft = y_pred_soft.argmax(dim=1)\n",
    "    if y_true.ndim == 2:\n",
    "        y_true = y_true.argmax(dim=1)\n",
    "    \n",
    "    tp = (y_true * y_pred_soft).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred_soft).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    #f1.requires_grad = is_training\n",
    "    return f1"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4gpy9GjCVKP",
    "outputId": "1bb274cc-ff16-4298-90ca-436c5965ca7e"
   },
   "source": [
    "print(test_data)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(test_data.Gender.values))\n",
    "\n",
    "#Create Dataloader\n",
    "test_tensor = data_process(test_data.Name.values, embedding_size)\n",
    "test_data_normalized = torch.FloatTensor(scaler.fit_transform(test_tensor))\n",
    "test_tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(test_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "test_dataset = TensorDataset(test_data_normalized, test_tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "                  Name  Gender\n",
      "20199               Ar       0\n",
      "2786                Lc       0\n",
      "3902                Si       0\n",
      "8554                Ji       0\n",
      "19970               Za       0\n",
      "...                ...     ...\n",
      "14096  Christiananthon       0\n",
      "18070  Christianalexan       0\n",
      "16548  Matthewalexande       0\n",
      "10920  Ashleyelizabeth       1\n",
      "11332  Christopherryan       0\n",
      "\n",
      "[20822 rows x 2 columns]\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b_Qghcb4GXxy"
   },
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2e_TX7uGi1s",
    "outputId": "5de49fdc-5d8e-41fa-cc37-90a9081efc48"
   },
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss, test_acc = evaluate_model(model, loader, loss_function)\n",
    "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 63.70%\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iUnmHf6JGvyZ"
   },
   "source": [
    "def evaluate_model(model, data_batches, loss_function):\n",
    "  eval_loss = 0\n",
    "  eval_acc = 0\n",
    "  \n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in data_batches:\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      predictions = model(batch[0]).squeeze(1)\n",
    "      for j in range(predictions.shape[0]):\n",
    "          predicted = np.argmax(F.softmax(predictions[j].data))\n",
    "          true = np.argmax(batch[1][j].data)\n",
    "          if (predicted == true):\n",
    "            correct+=1\n",
    "          total+=1\n",
    "      loss = loss_function(predictions, batch[1])\n",
    "      \n",
    "      #acc = accuracy_calculator(predictions, batch[1])\n",
    "      eval_loss += loss.item()\n",
    "      eval_acc += (correct / total)\n",
    "  \n",
    "  return eval_loss / len(data_batches), eval_acc / len(data_batches)"
   ],
   "execution_count": 53,
   "outputs": []
  }
 ]
}