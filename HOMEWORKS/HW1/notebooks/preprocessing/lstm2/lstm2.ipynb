{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "FGe2gp1dLS0o"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-pY-SEgiLUm7"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./train_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "test_data = pd.read_csv(\"./test_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "\n",
    "test_data['Gender'] = test_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "train_data['Gender'] = train_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "\n",
    "\n",
    "#print(train_data.shape)\n",
    "#train_data = train_data[:1280]\n",
    "#test_data = test_data[:1280]\n",
    "#print(train_data.shape)\n",
    "\n",
    "train_data = train_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "test_data = test_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "\n",
    "max_length_test = len(test_data.iloc[-1]['Name'])\n",
    "max_length_train = len(train_data.iloc[-1]['Name'])\n",
    "max_length = max(max_length_test, max_length_train)\n",
    "\n",
    "unique = list(set(\"\".join(train_data.iloc[:,0])))\n",
    "unique.sort()\n",
    "vocab = dict(zip(unique, range(1,len(unique)+1)))\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "vocab_new = Vocab(vocab,specials=())\n",
    "\n",
    "def data_process(raw_text_iter,max_len=128):\n",
    "  batch = []\n",
    "  for item in raw_text_iter:\n",
    "    res = []\n",
    "    for i in range(max_len):\n",
    "      if (len(item)>i):\n",
    "        res.extend([vocab_new[token] for token in tokenizer(item[i])])\n",
    "      else:\n",
    "        res.extend([0])\n",
    "    batch.append(res)\n",
    "  pad_data = torch.FloatTensor(batch)\n",
    "  return pad_data\n"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7ui39RsLWkd",
    "outputId": "84628131-c3b6-4c5d-d435-f9b8477eec51"
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(train_data.Gender.values))\n",
    "\n",
    "train_tensor = data_process(train_data.Name.values, embedding_size)\n",
    "train_data_normalized = torch.FloatTensor(scaler.fit_transform(train_tensor))\n",
    "tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(train_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "dataset = TensorDataset(train_data_normalized, tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]],\n",
      "       dtype=torch.float64)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u7lS3gupLY_1"
   },
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "  def __init__(self, input_size=max_length, hidden_layer_size=100, output_size=2, vocab_size=52, embedding_dim = max_length):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "  def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions\n"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "avkVhabSX-Ck"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkSFxkDVLbg4",
    "outputId": "efe475d0-2080-4bad-be00-be834be84722"
   },
   "source": [
    "import time \n",
    "import torch.nn.functional as F\n",
    "start_time = time.time()\n",
    "\n",
    "lrs =  [0.001]\n",
    "max_epochs =  [50]\n",
    "loss_functions = [nn.BCEWithLogitsLoss()]\n",
    "n_layers = [200]\n",
    "\n",
    "for epochs in max_epochs:\n",
    "  for lr in lrs:\n",
    "      for loss_function in loss_functions:\n",
    "        for hidden_layer_size in n_layers:\n",
    "          model = LSTM(hidden_layer_size=hidden_layer_size, embedding_dim = max_length)\n",
    "          optimizers = [torch.optim.Adam(model.parameters(), lr)]\n",
    "          for optimizer in optimizers:\n",
    "            print(\"MODEL\")\n",
    "            #print(\"__________________________________________________________\")\n",
    "            #print(\"Parameters:\")\n",
    "            #print(\"Amount of epochs\", epochs)\n",
    "            #print(\"Learning rate\", lr)\n",
    "            #print(\"Loss function\", loss_function)\n",
    "            #print(\"Hidden layer size\", hidden_layer_size)\n",
    "            #print(\"Optimizer\", optimizer)\n",
    "            for i in range(epochs):\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                start_epoch = time.time()\n",
    "                for item in loader:\n",
    "                    seq = item[0]\n",
    "                    label = item[1]\n",
    "                    optimizer.zero_grad()\n",
    "                    model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                                    torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "                    y_pred = model(seq)\n",
    "                    for j in range(y_pred.shape[0]):\n",
    "                      predicted = np.argmax(F.softmax(y_pred[j].data))\n",
    "                      true = np.argmax(label[j].data)\n",
    "                      if (predicted == true):\n",
    "                        correct+=1\n",
    "                      total+=1\n",
    "                    single_loss = loss_function(y_pred, label.float())\n",
    "                    single_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                time_per_epoch = time.time() - start_epoch\n",
    "                f_measure = f1_loss(label, y_pred)\n",
    "                writer.add_scalar(\"train_loss\", single_loss.item(), i)\n",
    "                writer.add_scalar(\"train_acc\", (100 * correct / total), i)\n",
    "                writer.add_scalar(\"train_measure\", f_measure, i)\n",
    "                writer.add_scalar(\"train_time\", time_per_epoch, i)\n",
    "                for tag, parm in model.named_parameters():\n",
    "                  writer.add_histogram(tag, parm.grad.data.cpu().numpy(), i)\n",
    "                print(f'epoch: {i:3} loss: {single_loss.item():10.8f}, accuracy: {(100 * correct / total)}, f-measure: {f_measure}, time = {time_per_epoch}')\n",
    "\n",
    "            print(\"MODEL TIME EXECUTION--- %s seconds ---\" % (time.time() - start_time))\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "            print()\n",
    "            print()"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "MODEL\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.63993907, accuracy: 63.13514551916242, f-measure: 0.583079993724823, time = 60.242557525634766\n",
      "epoch:   1 loss: 0.67196643, accuracy: 66.07074248391125, f-measure: 0.5740821957588196, time = 59.87481498718262\n",
      "epoch:   2 loss: 0.61587483, accuracy: 68.22831620401499, f-measure: 0.6094438433647156, time = 59.7031147480011\n",
      "epoch:   3 loss: 0.57298601, accuracy: 69.23446354817021, f-measure: 0.6424314975738525, time = 59.26805830001831\n",
      "epoch:   4 loss: 0.63312477, accuracy: 69.69551435981174, f-measure: 0.6155411601066589, time = 59.846014976501465\n",
      "epoch:   5 loss: 0.48727772, accuracy: 70.02929593698973, f-measure: 0.704352855682373, time = 60.17271399497986\n",
      "epoch:   6 loss: 0.53815603, accuracy: 70.29464028431467, f-measure: 0.6564878821372986, time = 59.810712814331055\n",
      "epoch:   7 loss: 0.53873920, accuracy: 70.53597156853328, f-measure: 0.684174656867981, time = 59.927377700805664\n",
      "epoch:   8 loss: 0.50017798, accuracy: 70.89736816828355, f-measure: 0.7112499475479126, time = 60.243823528289795\n",
      "epoch:   9 loss: 0.55047554, accuracy: 71.1855249255595, f-measure: 0.6649121642112732, time = 59.754141092300415\n",
      "epoch:  10 loss: 0.55353695, accuracy: 71.40884641244837, f-measure: 0.6619026064872742, time = 59.96381139755249\n",
      "epoch:  11 loss: 0.44943064, accuracy: 71.52530976851408, f-measure: 0.7284248471260071, time = 59.41468286514282\n",
      "epoch:  12 loss: 0.51763898, accuracy: 71.77984823744117, f-measure: 0.6937740445137024, time = 59.79726052284241\n",
      "epoch:  13 loss: 0.54768556, accuracy: 71.81466717894534, f-measure: 0.6802136301994324, time = 59.94105410575867\n",
      "epoch:  14 loss: 0.48555213, accuracy: 71.92392661607914, f-measure: 0.7070400714874268, time = 59.765933990478516\n",
      "epoch:  15 loss: 0.49900618, accuracy: 72.04279127845548, f-measure: 0.6967825293540955, time = 59.9324631690979\n",
      "epoch:  16 loss: 0.54166114, accuracy: 72.15685332821054, f-measure: 0.6755838990211487, time = 59.37722182273865\n",
      "epoch:  17 loss: 0.44994944, accuracy: 72.1892709634041, f-measure: 0.7451325058937073, time = 59.62391138076782\n",
      "epoch:  18 loss: 0.46805304, accuracy: 72.31774085102296, f-measure: 0.7179246544837952, time = 60.342437505722046\n",
      "epoch:  19 loss: 0.48551512, accuracy: 72.3645663240803, f-measure: 0.7103017568588257, time = 60.638142585754395\n",
      "epoch:  20 loss: 0.48148096, accuracy: 72.31293823840168, f-measure: 0.7052401900291443, time = 60.0218243598938\n",
      "epoch:  21 loss: 0.58256167, accuracy: 72.51945058111613, f-measure: 0.6607856154441833, time = 60.20398426055908\n",
      "epoch:  22 loss: 0.50227267, accuracy: 72.5542695226203, f-measure: 0.6953282952308655, time = 60.224862575531006\n",
      "epoch:  23 loss: 0.64995199, accuracy: 72.57828258572664, f-measure: 0.6178708672523499, time = 60.393601417541504\n",
      "epoch:  24 loss: 0.54711628, accuracy: 72.64071654980309, f-measure: 0.6731113791465759, time = 59.77497386932373\n",
      "epoch:  25 loss: 0.50535244, accuracy: 72.77999231581981, f-measure: 0.6947646737098694, time = 59.42052459716797\n",
      "epoch:  26 loss: 0.56137204, accuracy: 72.72956488329652, f-measure: 0.6584920287132263, time = 59.63316750526428\n",
      "epoch:  27 loss: 0.44145057, accuracy: 72.81120929785803, f-measure: 0.7463741898536682, time = 59.389472246170044\n",
      "epoch:  28 loss: 0.60147768, accuracy: 72.94328114494284, f-measure: 0.6537368893623352, time = 58.74232268333435\n",
      "epoch:  29 loss: 0.51377219, accuracy: 73.00091249639804, f-measure: 0.7069911956787109, time = 58.996052503585815\n",
      "epoch:  30 loss: 0.44364613, accuracy: 72.93127461338969, f-measure: 0.743296205997467, time = 59.72458291053772\n",
      "epoch:  31 loss: 0.47925720, accuracy: 73.03333013159158, f-measure: 0.7146367430686951, time = 59.38993859291077\n",
      "epoch:  32 loss: 0.54420769, accuracy: 72.96969551435981, f-measure: 0.6621070504188538, time = 59.12618541717529\n",
      "epoch:  33 loss: 0.46428564, accuracy: 73.00091249639804, f-measure: 0.7325573563575745, time = 59.109333992004395\n",
      "epoch:  34 loss: 0.47935802, accuracy: 73.10416866775526, f-measure: 0.7055442333221436, time = 58.74896216392517\n",
      "epoch:  35 loss: 0.54500729, accuracy: 73.21462875804437, f-measure: 0.6661267876625061, time = 58.794968605041504\n",
      "epoch:  36 loss: 0.57205546, accuracy: 73.19541830755931, f-measure: 0.6646891236305237, time = 58.91424775123596\n",
      "epoch:  37 loss: 0.57823139, accuracy: 73.26505619056766, f-measure: 0.6255629062652588, time = 59.473469257354736\n",
      "epoch:  38 loss: 0.57288772, accuracy: 73.13538564979349, f-measure: 0.6721209287643433, time = 58.698450326919556\n",
      "epoch:  39 loss: 0.49758193, accuracy: 73.2602535779464, f-measure: 0.6871222257614136, time = 58.53460097312927\n",
      "epoch:  40 loss: 0.51098293, accuracy: 73.26505619056766, f-measure: 0.6767129302024841, time = 59.163652420043945\n",
      "epoch:  41 loss: 0.51946086, accuracy: 73.2962731726059, f-measure: 0.6836944222450256, time = 58.23652911186218\n",
      "epoch:  42 loss: 0.53305286, accuracy: 73.29507251945058, f-measure: 0.6952919363975525, time = 58.78160762786865\n",
      "epoch:  43 loss: 0.45599651, accuracy: 73.3695130150802, f-measure: 0.7219591736793518, time = 59.01403212547302\n",
      "epoch:  44 loss: 0.56811804, accuracy: 73.32628950148882, f-measure: 0.6599988341331482, time = 59.39940810203552\n",
      "epoch:  45 loss: 0.47389415, accuracy: 73.39592738449717, f-measure: 0.7278932929039001, time = 59.36285591125488\n",
      "epoch:  46 loss: 0.47744352, accuracy: 73.43915089808856, f-measure: 0.7229138016700745, time = 59.14748191833496\n",
      "epoch:  47 loss: 0.57321316, accuracy: 73.51719335318413, f-measure: 0.6423588395118713, time = 58.919800758361816\n",
      "epoch:  48 loss: 0.62994790, accuracy: 73.56521947939679, f-measure: 0.6327106952667236, time = 59.21143651008606\n",
      "epoch:  49 loss: 0.55625796, accuracy: 73.58322927672654, f-measure: 0.7049744129180908, time = 59.25893759727478\n",
      "MODEL TIME EXECUTION--- 2978.256618499756 seconds ---\n",
      "epoch:  49 loss: 0.5562579632\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q3hOc5ECYzTb"
   },
   "source": [
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    all = y_pred.shape[0]\n",
    "    sum=0\n",
    "    for i in range(all):\n",
    "      sum+=f1_loss_one(y_true[i], y_pred[i])\n",
    "    return sum/all\n",
    "\n",
    "def f1_loss_one(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    y_pred_soft = (F.softmax(((y_pred)), dim=0)).detach()\n",
    "    if y_pred_soft.ndim == 2:\n",
    "        y_pred_soft = y_pred_soft.argmax(dim=1)\n",
    "    if y_true.ndim == 2:\n",
    "        y_true = y_true.argmax(dim=1)\n",
    "    \n",
    "    tp = (y_true * y_pred_soft).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred_soft).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    #f1.requires_grad = is_training\n",
    "    return f1"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7m_qS-MIY2pV",
    "outputId": "3642b2e3-5f32-4d8b-8a6b-1caa53f347af"
   },
   "source": [
    "print(test_data)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(test_data.Gender.values))\n",
    "\n",
    "#Create Dataloader\n",
    "test_tensor = data_process(test_data.Name.values, embedding_size)\n",
    "test_data_normalized = torch.FloatTensor(scaler.fit_transform(test_tensor))\n",
    "test_tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(test_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "test_dataset = TensorDataset(test_data_normalized, test_tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "                  Name  Gender\n",
      "20199               Ar       0\n",
      "2786                Lc       0\n",
      "3902                Si       0\n",
      "8554                Ji       0\n",
      "19970               Za       0\n",
      "...                ...     ...\n",
      "14096  Christiananthon       0\n",
      "18070  Christianalexan       0\n",
      "16548  Matthewalexande       0\n",
      "10920  Ashleyelizabeth       1\n",
      "11332  Christopherryan       0\n",
      "\n",
      "[20822 rows x 2 columns]\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SD6YYmX7Y3zO"
   },
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3Dop95WuY6GU"
   },
   "source": [
    "def evaluate_model(model, data_batches, loss_function):\n",
    "  eval_loss = 0\n",
    "  eval_acc = 0\n",
    "  \n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in data_batches:\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      predictions = model(batch[0])\n",
    "      for j in range(predictions.shape[0]):\n",
    "          predicted = np.argmax(F.softmax(predictions[j].data))\n",
    "          true = np.argmax(batch[1][j].data)\n",
    "          if (predicted == true):\n",
    "            correct+=1\n",
    "          total+=1\n",
    "      loss = loss_function(predictions, batch[1].float())\n",
    "      \n",
    "      #acc = accuracy_calculator(predictions, batch[1])\n",
    "      eval_loss += loss.item()\n",
    "      eval_acc += (correct / total)\n",
    "  \n",
    "  return eval_loss / len(data_batches), eval_acc / len(data_batches)"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9sevirwY8au",
    "outputId": "28025dd6-0b8b-4e5f-a646-86039633412e"
   },
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "loss = nn.MSELoss()\n",
    "test_loss, test_acc = evaluate_model(model, loader, loss_functions[0])\n",
    "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 63.42%\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}