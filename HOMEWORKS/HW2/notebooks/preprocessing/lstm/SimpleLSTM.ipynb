{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "SimpleLSTM ACTUAL.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "DvabwZo4WyA5"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQ4xzNf7WVud"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./train_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "test_data = pd.read_csv(\"./test_eng.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Name\",\"Gender\"])\n",
    "\n",
    "test_data['Gender'] = test_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "train_data['Gender'] = train_data['Gender'].apply(lambda x: 0 if x=='M' else 1)\n",
    "\n",
    "\n",
    "#print(train_data.shape)\n",
    "#train_data = train_data[:1280]\n",
    "#test_data = test_data[:1280]\n",
    "#print(train_data.shape)\n",
    "\n",
    "train_data = train_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "test_data = test_data.sort_values(by=\"Name\", key=lambda x: x.str.len())\n",
    "\n",
    "max_length_test = len(test_data.iloc[-1]['Name'])\n",
    "max_length_train = len(train_data.iloc[-1]['Name'])\n",
    "max_length = max(max_length_test, max_length_train)\n",
    "\n",
    "unique = list(set(\"\".join(train_data.iloc[:,0])))\n",
    "unique.sort()\n",
    "vocab = dict(zip(unique, range(1,len(unique)+1)))\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "vocab_new = Vocab(vocab,specials=())\n",
    "\n",
    "def data_process(raw_text_iter,max_len=128):\n",
    "  batch = []\n",
    "  for item in raw_text_iter:\n",
    "    res = []\n",
    "    for i in range(max_len):\n",
    "      if (len(item)>i):\n",
    "        res.extend([vocab_new[token] for token in tokenizer(item[i])])\n",
    "      else:\n",
    "        res.extend([0])\n",
    "    batch.append(res)\n",
    "  pad_data = torch.FloatTensor(batch)\n",
    "  return pad_data\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "8E1ASwk_3muG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "21f47fac-7657-4841-81f2-96b3e1513ac6"
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(train_data.Gender.values))\n",
    "\n",
    "train_tensor = data_process(train_data.Name.values, embedding_size)\n",
    "train_data_normalized = torch.FloatTensor(scaler.fit_transform(train_tensor))\n",
    "tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(train_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "dataset = TensorDataset(train_data_normalized, tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]])\n",
      "\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "\n",
      "tensor([[ 0.9200,  0.5200, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.9200,  0.6800, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.8400,  0.4400, -0.3600,  ...,  0.3600,  0.8400,  0.4400],\n",
      "        [ 0.2000,  0.6800, -0.6800,  ..., -0.2000,  0.4400,  0.6800],\n",
      "        [ 0.2800, -0.1200, -0.0400,  ...,  1.0000,  0.6800,  0.1200]],\n",
      "       dtype=torch.float64)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ozGVnOulrvha"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "l1Iofjq13muG"
   },
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "  def __init__(self, input_size=max_length, hidden_layer_size=100, output_size=2):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "  def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions\n",
    "\n",
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2bJzJbOCNqXF"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nH3HtEEmopHn",
    "outputId": "88308698-ada2-4b54-ebb8-47785031c0f8"
   },
   "source": [
    "epochs = 50\n",
    "import time \n",
    "import torch.nn.functional as F\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_epoch = time.time()\n",
    "    for item in loader:\n",
    "        seq = item[0]\n",
    "        label = item[1]\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "        for j in range(y_pred.shape[0]):\n",
    "          predicted = np.argmax(F.softmax(y_pred[j].data))\n",
    "          true = np.argmax(label[j].data)\n",
    "          if (predicted == true):\n",
    "            correct+=1\n",
    "          total+=1\n",
    "        single_loss = loss_function(y_pred, label.float())\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    time_per_epoch = time.time() - start_epoch\n",
    "    f_measure = f1_loss(label, y_pred)\n",
    "    writer.add_scalar(\"train_loss\", single_loss.item(), i)\n",
    "    writer.add_scalar(\"train_acc\", (100 * correct / total), i)\n",
    "    writer.add_scalar(\"train_measure\", f_measure, i)\n",
    "    writer.add_scalar(\"train_time\", time_per_epoch, i)\n",
    "    for tag, parm in model.named_parameters():\n",
    "      writer.add_histogram(tag, parm.grad.data.cpu().numpy(), i)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}, accuracy: {(100 * correct / total)}, f-measure: {f_measure}, time = {time_per_epoch}')\n",
    "\n",
    "print(\"MODEL TIME EXECUTION--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.22744991, accuracy: 63.240802996830276, f-measure: 0.5273582339286804, time = 38.57597589492798\n",
      "epoch:   1 loss: 0.22572528, accuracy: 65.60608971280377, f-measure: 0.5306821465492249, time = 28.163079977035522\n",
      "epoch:   2 loss: 0.17508495, accuracy: 68.01459994236865, f-measure: 0.5591893792152405, time = 27.99694514274597\n",
      "epoch:   3 loss: 0.18287085, accuracy: 69.07837863797906, f-measure: 0.5567010641098022, time = 27.788639545440674\n",
      "epoch:   4 loss: 0.19746009, accuracy: 69.56584381903755, f-measure: 0.5436967611312866, time = 28.022472143173218\n",
      "epoch:   5 loss: 0.18945123, accuracy: 69.74714244549034, f-measure: 0.5626565217971802, time = 28.18270182609558\n",
      "epoch:   6 loss: 0.20498942, accuracy: 69.93564499087503, f-measure: 0.5506161451339722, time = 28.06424880027771\n",
      "epoch:   7 loss: 0.17943515, accuracy: 70.20459129766593, f-measure: 0.5645135045051575, time = 28.614763736724854\n",
      "epoch:   8 loss: 0.19083315, accuracy: 70.36427816732302, f-measure: 0.5516542196273804, time = 28.344443798065186\n",
      "epoch:   9 loss: 0.19270368, accuracy: 70.67044472192873, f-measure: 0.5610694885253906, time = 28.477715015411377\n",
      "epoch:  10 loss: 0.18635462, accuracy: 70.83373355105178, f-measure: 0.5552825927734375, time = 28.832077980041504\n",
      "epoch:  11 loss: 0.14417405, accuracy: 71.16151186245317, f-measure: 0.5834570527076721, time = 28.188833713531494\n",
      "epoch:  12 loss: 0.21150270, accuracy: 71.39323792142926, f-measure: 0.5496159195899963, time = 28.045708894729614\n",
      "epoch:  13 loss: 0.18967858, accuracy: 71.52170780904812, f-measure: 0.558833658695221, time = 28.05795121192932\n",
      "epoch:  14 loss: 0.15260047, accuracy: 71.72221688598597, f-measure: 0.5780237317085266, time = 28.0561306476593\n",
      "epoch:  15 loss: 0.21195954, accuracy: 71.76544039957737, f-measure: 0.5379846096038818, time = 28.53888964653015\n",
      "epoch:  16 loss: 0.17066909, accuracy: 71.9863605801556, f-measure: 0.5687142014503479, time = 28.292980909347534\n",
      "epoch:  17 loss: 0.14625718, accuracy: 72.08361348573624, f-measure: 0.586341917514801, time = 28.211642026901245\n",
      "epoch:  18 loss: 0.16858736, accuracy: 72.24450100854865, f-measure: 0.5734044313430786, time = 28.37364673614502\n",
      "epoch:  19 loss: 0.24363813, accuracy: 72.25050427432524, f-measure: 0.5499051809310913, time = 28.13687491416931\n",
      "epoch:  20 loss: 0.19862634, accuracy: 72.2481029680146, f-measure: 0.5482593774795532, time = 28.189301013946533\n",
      "epoch:  21 loss: 0.21948762, accuracy: 72.50144078378638, f-measure: 0.5461651086807251, time = 28.167745113372803\n",
      "epoch:  22 loss: 0.17740576, accuracy: 72.41379310344827, f-measure: 0.5736278891563416, time = 28.212504386901855\n",
      "epoch:  23 loss: 0.14970757, accuracy: 72.53265776582461, f-measure: 0.5880575776100159, time = 28.261462211608887\n",
      "epoch:  24 loss: 0.23033255, accuracy: 72.53385841897993, f-measure: 0.5412635207176208, time = 28.30124258995056\n",
      "epoch:  25 loss: 0.22488037, accuracy: 72.62750936509461, f-measure: 0.5383986830711365, time = 28.134655475616455\n",
      "epoch:  26 loss: 0.19781376, accuracy: 72.65632504082221, f-measure: 0.5544350147247314, time = 28.471721172332764\n",
      "epoch:  27 loss: 0.15807500, accuracy: 72.56627605417347, f-measure: 0.5809302926063538, time = 28.464839220046997\n",
      "epoch:  28 loss: 0.19566379, accuracy: 72.69474594179233, f-measure: 0.5651330351829529, time = 28.399747371673584\n",
      "epoch:  29 loss: 0.18358575, accuracy: 72.73076553645183, f-measure: 0.5649961829185486, time = 28.427224159240723\n",
      "epoch:  30 loss: 0.16583620, accuracy: 72.78359427528575, f-measure: 0.5715538263320923, time = 28.276339530944824\n",
      "epoch:  31 loss: 0.19285212, accuracy: 72.7727883968879, f-measure: 0.5630379319190979, time = 28.32492733001709\n",
      "epoch:  32 loss: 0.18838014, accuracy: 72.7715877437326, f-measure: 0.5606681704521179, time = 28.284510374069214\n",
      "epoch:  33 loss: 0.16080473, accuracy: 72.90966285659398, f-measure: 0.5791370272636414, time = 28.458449602127075\n",
      "epoch:  34 loss: 0.18204628, accuracy: 72.87844587455575, f-measure: 0.5599951148033142, time = 28.38603377342224\n",
      "epoch:  35 loss: 0.19228645, accuracy: 72.88324848717703, f-measure: 0.5589052438735962, time = 28.46427059173584\n",
      "epoch:  36 loss: 0.19243620, accuracy: 72.94808375756412, f-measure: 0.5584085583686829, time = 28.432990550994873\n",
      "epoch:  37 loss: 0.18995146, accuracy: 72.81961386994524, f-measure: 0.5628471970558167, time = 28.616586446762085\n",
      "epoch:  38 loss: 0.18038367, accuracy: 72.90005763135146, f-measure: 0.5768521428108215, time = 28.76977229118347\n",
      "epoch:  39 loss: 0.19183196, accuracy: 72.99490923062146, f-measure: 0.5598198175430298, time = 29.199976921081543\n",
      "epoch:  40 loss: 0.18330814, accuracy: 73.12457977139564, f-measure: 0.564625084400177, time = 28.972556352615356\n",
      "epoch:  41 loss: 0.18343973, accuracy: 73.10656997406589, f-measure: 0.5766637921333313, time = 28.738535404205322\n",
      "epoch:  42 loss: 0.15879537, accuracy: 73.02852751897032, f-measure: 0.5821893215179443, time = 28.42836356163025\n",
      "epoch:  43 loss: 0.18230037, accuracy: 73.09096148304678, f-measure: 0.5638387203216553, time = 28.412446975708008\n",
      "epoch:  44 loss: 0.15741540, accuracy: 73.08255691095957, f-measure: 0.5875431299209595, time = 28.50971269607544\n",
      "epoch:  45 loss: 0.18032640, accuracy: 73.03092882528095, f-measure: 0.5713967680931091, time = 28.501277923583984\n",
      "epoch:  46 loss: 0.19394055, accuracy: 73.04533666314475, f-measure: 0.5637479424476624, time = 28.352405786514282\n",
      "epoch:  47 loss: 0.17670311, accuracy: 73.18101046969551, f-measure: 0.5800223350524902, time = 28.52566361427307\n",
      "epoch:  48 loss: 0.16404863, accuracy: 73.17620785707425, f-measure: 0.5832912921905518, time = 28.451372385025024\n",
      "epoch:  49 loss: 0.17363995, accuracy: 73.15939871289982, f-measure: 0.5661537647247314, time = 29.00792121887207\n",
      "MODEL TIME EXECUTION--- 1430.7409045696259 seconds ---\n",
      "epoch:  49 loss: 0.1736399531\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kfmCaRgPgwZV"
   },
   "source": [
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    all = y_pred.shape[0]\n",
    "    sum=0\n",
    "    for i in range(all):\n",
    "      sum+=f1_loss_one(y_true[i], y_pred[i])\n",
    "    return sum/all\n",
    "\n",
    "def f1_loss_one(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    y_pred_soft = (F.softmax(((y_pred)), dim=0)).detach()\n",
    "    if y_pred_soft.ndim == 2:\n",
    "        y_pred_soft = y_pred_soft.argmax(dim=1)\n",
    "    if y_true.ndim == 2:\n",
    "        y_true = y_true.argmax(dim=1)\n",
    "    \n",
    "    tp = (y_true * y_pred_soft).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred_soft).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred_soft)).sum().to(torch.float32)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    #f1.requires_grad = is_training\n",
    "    return f1"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1Ph6RR2gxc-",
    "outputId": "271ed64c-a275-46c8-e875-4cc228317dcc"
   },
   "source": [
    "print(test_data)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "max_len = 64\n",
    "embedding_size = max(max_length_train, max_length_test)\n",
    "n_classes = len(np.unique(test_data.Gender.values))\n",
    "\n",
    "test_tensor = data_process(test_data.Name.values, embedding_size)\n",
    "test_data_normalized = torch.FloatTensor(scaler.fit_transform(test_tensor))\n",
    "test_tgts_tensor = torch.nn.functional.one_hot(torch.from_numpy(test_data.Gender.values), n_classes) #torch.from_numpy(train_data.Target.values)\n",
    "\n",
    "test_dataset = TensorDataset(test_data_normalized, test_tgts_tensor)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "                  Name  Gender\n",
      "20199               Ar       0\n",
      "2786                Lc       0\n",
      "3902                Si       0\n",
      "8554                Ji       0\n",
      "19970               Za       0\n",
      "...                ...     ...\n",
      "14096  Christiananthon       0\n",
      "18070  Christianalexan       0\n",
      "16548  Matthewalexande       0\n",
      "10920  Ashleyelizabeth       1\n",
      "11332  Christopherryan       0\n",
      "\n",
      "[20822 rows x 2 columns]\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "tensor([[ 1.0000, -0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.1200,  0.8400, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        [-0.4400,  0.3600, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0400,  1.0000, -0.5200,  ..., -0.0400,  0.7600,  1.0000],\n",
      "        [ 1.0000, -0.4400,  0.4400,  ...,  0.6800, -0.5200,  0.7143],\n",
      "        [ 0.8400,  0.4400, -0.3600,  ..., -0.9200,  1.0000,  0.1429]])\n",
      "\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XdU2Idi8Oh0p"
   },
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7M9dfOHzOipf"
   },
   "source": [
    "def evaluate_model(model, data_batches, loss_function):\n",
    "  eval_loss = 0\n",
    "  eval_acc = 0\n",
    "  \n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in data_batches:\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      predictions = model(batch[0]).squeeze(1)\n",
    "      for j in range(predictions.shape[0]):\n",
    "          predicted = np.argmax(F.softmax(predictions[j].data))\n",
    "          true = np.argmax(batch[1][j].data)\n",
    "          if (predicted == true):\n",
    "            correct+=1\n",
    "          total+=1\n",
    "      loss = loss_function(predictions, batch[1])\n",
    "      eval_loss += loss.item()\n",
    "      eval_acc += (correct / total)\n",
    "  \n",
    "  return eval_loss / len(data_batches), eval_acc / len(data_batches)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGrvAmAsOk3F",
    "outputId": "2c22ad98-a79c-43b8-d3f3-236283ad1ba0"
   },
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss, test_acc = evaluate_model(model, loader, loss_function)\n",
    "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 73.29%\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}