{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elizaveta55/DS/blob/master/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SMM2RQWYh-0"
      },
      "source": [
        "### Week 3: Reccurent Neural Networks\n",
        "```\n",
        "- Advanced Machine Learning, Innopolis University \n",
        "- Professor: Muhammad Fahim \n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "\n",
        "```\n",
        "Lab Plan\n",
        "1. Movie Sentiment Analysis\n",
        "    a. Dataset\n",
        "    b. Data Preprocessing\n",
        "    c. PyTorch RNN \n",
        "    d. Keras Simple Neural Network \n",
        "    e. Keras Convolutional Neural Network\n",
        "    f. Lab Task\n",
        "```\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edS-8CFYcAe"
      },
      "source": [
        "## Dataset Description\n",
        "\n",
        "[IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/) having 50K movie reviews for natural language processing or Text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX8Y56qHYcAl"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "[`torchtext`](https://pytorch.org/text/stable/index.html) is a package that consists of data processing utilities and popular datasets for natural language\n",
        "\n",
        "One of the main concepts of TorchText is the `Field`. To define how the data should be processed we will use `Field`. Our input data contains raw strings <br>\n",
        "The declared `TEXT` field defines how the review should be processed, and the `LABEL` field to process the sentiment. \n",
        "\n",
        "For more on `Fields`, go [here](https://github.com/pytorch/text/blob/master/torchtext/data/field.py).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFGKi6vXYcAn"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Dg1WbbYcAn"
      },
      "source": [
        "## Download the data\n",
        "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as `torchtext.datasets` objects. It process the data using the `Fields` we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhMqmCDkYcAo",
        "outputId": "7dac0b1b-6ab4-44de-d6bc-16189e06440e"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "print(f'{len(train_data)} training examples')\n",
        "print(f'{len(test_data)} testing examples')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:13<00:00, 6.39MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 training examples\n",
            "25000 testing examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w42fi2uaYcAq",
        "outputId": "256a09eb-c4cc-462f-ca53-2c7ad3a91aec"
      },
      "source": [
        "print(vars(train_data.examples[5]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Despite', 'gorgeous', 'and', 'breathtaking', 'animation', ',', 'this', 'is', 'probably', 'one', 'of', 'most', 'uninspiring', 'Disney', 'films', 'I', \"'ve\", 'seen', ',', 'and', 'I', 'do', \"n't\", 'slam', 'Disney', 'films', 'very', 'often', '.', 'Spirit', 'is', 'a', 'wild', 'stallion', 'who', 'repeatedly', 'gets', 'captured', ',', 'either', 'by', 'the', 'cavalry', 'or', 'by', 'Indians', ',', 'both', 'of', 'which', 'try', 'to', '\"', 'break', '\"', 'him', '.', 'Spirit', 'ends', 'up', 'forming', 'a', 'bond', 'with', 'the', 'Indian', ',', 'and', 'that', ',', 'in', 'a', 'nutshell', ',', 'is', 'the', 'story', '.', 'With', 'exception', 'to', 'the', 'beautiful', 'animation', 'of', 'the', 'horses', ',', 'neither', 'I', 'or', 'my', 'five', 'year', 'old', 'were', 'very', 'inspired', 'or', 'excited', 'by', 'this', 'film', '.', 'It', \"'s\", 'ironic', 'that', 'it', \"'s\", 'titled', '\"', 'Spirit', '\"', ',', 'as', 'spirit', 'is', 'what', 'this', 'film', 'could', 'have', 'used', 'a', 'bit', 'more', 'of', '.', 'An', 'extra', 'point', 'was', 'given', 'for', 'the', 'soundtrack', ',', 'which', 'was', 'enjoyable', ',', 'with', 'songs', 'by', 'Bryan', 'Adams', 'and', 'Hans', 'Zimmer', '.', 'And', 'although', 'this', 'film', 'is', 'rated', 'G', ',', 'you', 'will', 'still', 'probably', 'have', 'to', 'end', 'up', 'explaining', 'what', '\"', 'breaking', 'a', 'horse', '\"', 'means', 'to', 'your', 'five', 'year', 'old', '.', 'I', 'did.<br', '/><br', '/', '>'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkUWxRVvYcAr"
      },
      "source": [
        "## Split the data to train and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnkIgmfwYcAr"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwt62cLYcAr"
      },
      "source": [
        "Again, we'll view how many examples are in each split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33-NKWj7YcAs",
        "outputId": "175a6714-ef68-410f-c20a-5b7986e61139"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGxi9kIYcAt"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "# TEXT.build_vocab(train_data, vectors='glove.6B.100d')\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc3K35fQYcAu"
      },
      "source": [
        "Why do we only build the vocabulary on the training set? When testing any machine learning system you do not want to look at the test set in any way. We do not include the validation set as we want it to reflect the test set as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiirlj6fYcAu",
        "outputId": "35c59d6d-8570-4df9-aeb0-c903626b912e"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0EGn7cwYcAw"
      },
      "source": [
        "We can also check the labels, 0 is for negative and 1 is for positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoB8WOCSYcAw",
        "outputId": "17121479-fb8f-4341-ca1f-5d14cf86ed41"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgjGe4DhYcAx"
      },
      "source": [
        "## Dataloders / Iterators \n",
        "\n",
        "* We have done preprocessing of the raw data but we have to create batches and convert the data to tensors. For text data Pytorch provides a container called `BucketIterator` for such task.\n",
        "\n",
        "* The `BucketIterator` will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
        "\n",
        "* To put the data into the training device, its neccesary to specify the device parameter in the `BucketIterator` then Pytorch will take care of the rest. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZarz-5NYcAx"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), \n",
        "    batch_size = batch_size,\n",
        "    device = device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxH-cBsQYcAx"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "The next stage is building the model that we'll eventually train and evaluate. \n",
        "\n",
        "There is a small amount of boilerplate code when creating models in PyTorch, note how our `RNN` class is a sub-class of `nn.Module` and the use of `super`.\n",
        "\n",
        "Within the `__init__` we define the _layers_ of the module. Our three layers are an _embedding_ layer, our RNN, and a _linear_ layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
        "\n",
        "\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKf7tztuYcAz"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.embedding_layer = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn_cell = nn.RNN(embedding_dim, hidden_dim)\n",
        "    self.fc_layer = nn.Linear(hidden_dim, output_dim)\n",
        "      \n",
        "  def forward(self, text):\n",
        "    \"\"\"\n",
        "    Foward pass\n",
        "    Args:\n",
        "        text:\n",
        "            sentiment text with shape [sentence length, batch size]\n",
        "    \"\"\"\n",
        "    embedded = self.embedding_layer(text) # embedding_layer output shape  (sentence length, batch size, embedding dim]\n",
        "    output, hidden = self.rnn_cell(embedded) # \n",
        "    \n",
        "    assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "    \n",
        "    return self.fc_layer(hidden.squeeze(0))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5G_zCcUYcA0"
      },
      "source": [
        "input_dim = len(TEXT.vocab) #input dimension is the dimension of the one-hot vectors\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256 #size of the hidden states\n",
        "output_dim = 1 # for the fully connected \n",
        "\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8mzk7joYcA1"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSjst1pIYcA2"
      },
      "source": [
        "import torch.optim as optim\n",
        "# define loss function and optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#make model instance and send it to training device\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gfwn1NiYcA3"
      },
      "source": [
        "# TODO: Implement accuracy_calculator which takes predicted labels and real labels\n",
        "def accuracy_calculator(preds, y):\n",
        "  #print(preds.get_session)\n",
        "  #print(preds.shape)\n",
        "  success = 0\n",
        "  all = preds.shape[0]\n",
        "  for i in range(preds.shape[0]):\n",
        "    #pred_numpy = preds[i].numpy\n",
        "    #y_numpy = y[i].numpy\n",
        "    #print(pred_numpy, y_numpy)\n",
        "    #print(preds[i], y[i])\n",
        "    if (preds[i] >= 0.5 and y[i]==1) or (preds[i] < 0.5 and y[i]==0):\n",
        "      success+=1\n",
        "  \"\"\"Returns accuracy per batch\"\"\"\n",
        "  return success/all"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVcX-RZiYcA4"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "\n",
        "    acc = accuracy_calculator(predictions, batch.label)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc\n",
        "      \n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJQQ4_lxYcA4"
      },
      "source": [
        "def evaluate_model(model, data_batches, criterion):\n",
        "  eval_loss = 0\n",
        "  eval_acc = 0\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch in data_batches:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      \n",
        "      acc = accuracy_calculator(predictions, batch.label)\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc\n",
        "  \n",
        "  return eval_loss / len(data_batches), eval_acc / len(data_batches)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwqbAPboYcA5",
        "outputId": "8b4a5a1b-7bd8-497f-ce3a-c314b3dde081"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate_model(model, valid_iterator, criterion)\n",
        "  \n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'best-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1} , Train [Loss:  {train_loss:.3f}  Acc :{train_acc*100:.2f}], Val.[Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}]')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 , Train [Loss:  0.693  Acc :50.36], Val.[Loss: 0.698 Acc: 49.22]\n",
            "Epoch: 2 , Train [Loss:  0.693  Acc :50.33], Val.[Loss: 0.698 Acc: 49.22]\n",
            "Epoch: 4 , Train [Loss:  0.693  Acc :50.33], Val.[Loss: 0.698 Acc: 49.22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPqbylW4zRCz"
      },
      "source": [
        "## Save and load model for Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1lECvJOYcA6",
        "outputId": "dd1b967e-3a6c-4721-d0db-6911001a3475"
      },
      "source": [
        "model.load_state_dict(torch.load('best-model.pt')) #Load the best model\n",
        "test_loss, test_acc = evaluate_model(model, test_iterator, criterion)\n",
        "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data : 49.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMeZxj-wCwqg"
      },
      "source": [
        "## More on Tensorflow and Keras\n",
        "```\n",
        "1. Data Preprocessing\n",
        "2. Simple Neural Network\n",
        "3. Convolutional Neural Network\n",
        "4. Recurrent Neural Network \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWqBtEhnDIyF"
      },
      "source": [
        "## Download, unzip and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "6WcXyrYUAFnf",
        "outputId": "9836d70a-e2a6-42da-91d1-a981708eafed"
      },
      "source": [
        "!pip install wget\n",
        "\n",
        "import pandas as pd\n",
        "import wget, zipfile\n",
        "\n",
        "wget.download('https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv')\n",
        "# !wget https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\n",
        "\n",
        "movie_reviews = pd.read_csv(\"IMDb_Reviews.csv\")\n",
        "movie_reviews.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=f12bc9a4518d9bc33fe6e2ceb209d864a024f1a90b71d6d794afd3b71168734e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "5Qn2raI4BZhM",
        "outputId": "6817e81a-aff9-4058-df92-a739d5c400a5"
      },
      "source": [
        "# TODO: See Visualize class distribution (balanced or not). i.e use matplotlib or plotly\n",
        "movie_reviews.plot.hist(by=\"sentiment\")\n",
        "print(movie_reviews[\"review\"][3])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One of the most unheralded great works of animation. Though it makes the most sophisticated use of the \"cut-out\" method of animation (a la \"South Park\"), the real talent behind \"Twice Upon a Time\" are the vocal characterizations, with Lorenzo Music's (Carlton from TV's \"Rhoda\") Woody Allen-ish Ralph-the-all-purpose-Animal being the centerpiece. The \"accidental nightmare\" sequence is doubtless one of the best pieces of animation ever filmed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jxwk0qtECL6"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcT1l3dZEWyR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, Conv1D, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfSiEcT1EAMh"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "  # Removing tags\n",
        "  sentence = remove_tags(sen)\n",
        "\n",
        "  # Remove punctuations and numbers\n",
        "  sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "  return TAG_RE.sub('', text)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-eSbNgPENDT"
      },
      "source": [
        "# Clean the data\n",
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "  X.append(preprocess_text(sen))\n",
        "\n",
        "#Split the data to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, movie_reviews['sentiment'].values, test_size=0.20, random_state=42)\n",
        "\n",
        "#Tokenize the data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PozGpmBQE7W7"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKRG1QCyFFdo"
      },
      "source": [
        "### Get pre-trained embeddings (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJwySSAyIxw0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c7343308-524e-4c0c-a32e-778a9d3c3abc"
      },
      "source": [
        "# TODO : Download Glove embeddings from http://nlp.stanford.edu/data/glove.6B.zip and unzip.\n",
        "\n",
        "wget.download('http://nlp.stanford.edu/data/glove.6B.zip')\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-dff633d27d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO : Download Glove embeddings from http://nlp.stanford.edu/data/glove.6B.zip and unzip.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://nlp.stanford.edu/data/glove.6B.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# !wget http://nlp.stanford.edu/data/glove.6B.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wget.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mbinurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtmpfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mulib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmpfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT7RY_EEZPrj"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvBbVKXFMMf"
      },
      "source": [
        "# Retrieve the embeddings and embedding matrix \n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in glove_file:\n",
        "  records = line.split()\n",
        "  word = records[0]\n",
        "  vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "  embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  embedding_vector = embeddings_dictionary.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEELt92qFf1d"
      },
      "source": [
        "### Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM4GbiQ3Fkbt",
        "outputId": "7b8eb885-a2c0-46be-c678-0d44eb14ff16"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Create, add Embedding layer and freeze it \n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "#Flatten the embedding output \n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Specify the optimizer, loss function and metric \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          9230300   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                640064    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 9,872,717\n",
            "Trainable params: 642,417\n",
            "Non-trainable params: 9,230,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdrmKl-F50Z",
        "outputId": "59405917-b7f2-4abd-b89c-4fd04df06bf3"
      },
      "source": [
        "# Train the model by calling the fit method. Specify the batch size, number of epochs and validation (optional)\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=0, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9816 - acc: 0.7046\n",
            "Test Score: 0.9816303849220276\n",
            "Test Accuracy: 0.7045999765396118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U74uKP4mbsix",
        "outputId": "e0da5624-1556-4f1e-aeab-3d46517e1690"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i33k8m5ncGAf",
        "outputId": "a2c96fec-ff18-49a1-dcc9-b012fbc54029"
      },
      "source": [
        "history.history['acc']"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6706874966621399,\n",
              " 0.7759374976158142,\n",
              " 0.8043749928474426,\n",
              " 0.8337500095367432,\n",
              " 0.8563125133514404,\n",
              " 0.8855624794960022,\n",
              " 0.9154062271118164,\n",
              " 0.9413437247276306,\n",
              " 0.9569374918937683,\n",
              " 0.9600937366485596]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E0FPWiLF_5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1895c58c-5552-47e9-ce69-69beedc5a2a6"
      },
      "source": [
        "#TODO: Visualize the accuracy and loss of the model using i.e matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], history.history['acc'])\n",
        "plt.show"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ktYL-UGRtw"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcs3L2c2GRIi",
        "outputId": "83cce2b5-17b9-402b-b8af-24ac48d9889a"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          9230300   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 9,294,557\n",
            "Trainable params: 64,257\n",
            "Non-trainable params: 9,230,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgsjjHTYG_wv",
        "outputId": "233f9c46-3cba-4efd-ee99-9718695a4f98"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=0, validation_split=0.2)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3472 - acc: 0.8464\n",
            "Test Score: 0.34719881415367126\n",
            "Test Accuracy: 0.8464000225067139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPPrL-YNHlMb"
      },
      "source": [
        "### Recurrent Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inLKlHMHHD56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2837fd4-58f4-4b47-bbb8-a2cc2ed5777a"
      },
      "source": [
        "#TODO(optional): Recurrent Neural Network (LSTM) \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(LSTM(10, dropout=0.2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          9230300   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10)                4440      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 9,234,751\n",
            "Trainable params: 4,451\n",
            "Non-trainable params: 9,230,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn9MZ6QRdgXW",
        "outputId": "86d8a383-0068-4386-dc52-ed7ec769771e"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=0, validation_split=0.2)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6693 - acc: 0.5982\n",
            "Test Score: 0.6693398356437683\n",
            "Test Accuracy: 0.5982000231742859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "y-aDzoWpdput",
        "outputId": "a25c0100-cde1-4230-f8f1-96e93533dc21"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], history.history['acc'])\n",
        "plt.show"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uK0GklzYcA6"
      },
      "source": [
        "## Lab Task\n",
        "```\n",
        "1. Make improvements of the current RNN by : \n",
        "  - Usin pre-trained word embeddings (GloVe)\n",
        "  - different RNN architecture\n",
        "  - multi-layer RNN or LSTM\n",
        "  - a different optimizer\n",
        "2. Calculate number of model parameters (traninable and non-trainable)\n",
        "3. Implement a method that will take a string (review sentence) and return a sentiment of that string\n",
        "\n",
        "**Try to get accuracy > 80%\n",
        "```\n",
        "\n",
        "<b>Note: </b> [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) <br>\n",
        "<center>Don't to forget to make a Git commit</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g4x1U7fd3KF",
        "outputId": "8da4b785-f357-431f-e01f-19cdf00e7ec4"
      },
      "source": [
        "#Implement a method that will take a string (review sentence) and return a sentiment of that string\n",
        "import tensorflow as tf\n",
        "\n",
        "query = \"some text\"\n",
        "query = preprocess_text(query)\n",
        "\n",
        "to_test_query = tokenizer.texts_to_sequences(query)\n",
        "\n",
        "to_test = pad_sequences(to_test_query, padding='post', maxlen=maxlen)\n",
        "prediction = model.predict(to_test)\n",
        "print(accuracy_calculator(prediction, [[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]))\n",
        "print(accuracy_calculator(prediction, [[0],[0],[0],[0],[0],[0],[0],[0],[0],[0]]))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLNTZebOI45W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}